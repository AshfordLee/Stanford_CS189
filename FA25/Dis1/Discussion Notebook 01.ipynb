{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28663ee",
   "metadata": {
    "id": "a28663ee"
   },
   "source": [
    "# Discussion 1: Pandas Review\n",
    "\n",
    "This section of Discussion 1 is meant to review [Pandas](https://pandas.pydata.org/docs/), one of the most popular Python libraries for data-wrangling. It's a crucial tool in any machine learning researcher or engineer's repertoire and you will continue to use it heavily throughout the semester.\n",
    "\n",
    "Let's start by loading the necessary packages for today's exercise, which will look at movie data from IMDb. We use the `read_csv` function to load data from the internet, but you can also use this function to load a file from your local storage.\n",
    "\n",
    "*NOTE: The output of the cells may not be correct if run out of order, even if your code is correct. If in doubt, you can run all cells at once, which should take no more than a few seconds.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4j-uJamRWD2Z",
   "metadata": {
    "id": "4j-uJamRWD2Z"
   },
   "outputs": [],
   "source": [
    "import os, random, numpy as np\n",
    "SEED = 189\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982be303",
   "metadata": {
    "id": "982be303"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpx\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the title_basics dataset from IMDb\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m title_basics  = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://datasets.imdbws.com/title.basics.tsv.gz\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgzip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mN\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500000\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Load the title_ratings dataset from IMDb\u001b[39;00m\n\u001b[32m     10\u001b[39m title_ratings = pd.read_csv(\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://datasets.imdbws.com/title.ratings.tsv.gz\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     sep=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m, compression=\u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m, na_values=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mN\u001b[39m\u001b[33m\"\u001b[39m, nrows=\u001b[32m500000\u001b[39m\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pandas/io/common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pandas/io/common.py:389\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    386\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m             \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n\u001b[32m    388\u001b[39m             compression = {\u001b[33m\"\u001b[39m\u001b[33mmethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m         reader = BytesIO(\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[32m    391\u001b[39m         filepath_or_buffer=reader,\n\u001b[32m    392\u001b[39m         encoding=encoding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m         mode=fsspec_mode,\n\u001b[32m    396\u001b[39m     )\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_fsspec_url(filepath_or_buffer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/http/client.py:495\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m         s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[32m    497\u001b[39m         \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/http/client.py:642\u001b[39m, in \u001b[36mHTTPResponse._safe_read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[32m    636\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[32m    637\u001b[39m \n\u001b[32m    638\u001b[39m \u001b[33;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[33;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[33;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < amt:\n\u001b[32m    644\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt-\u001b[38;5;28mlen\u001b[39m(data))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load the title_basics dataset from IMDb\n",
    "title_basics  = pd.read_csv(\n",
    "    \"https://datasets.imdbws.com/title.basics.tsv.gz\",\n",
    "    sep=\"\\t\", compression=\"gzip\", na_values=\"\\\\N\", nrows=500000\n",
    ")\n",
    "# Load the title_ratings dataset from IMDb\n",
    "title_ratings = pd.read_csv(\n",
    "    \"https://datasets.imdbws.com/title.ratings.tsv.gz\",\n",
    "    sep=\"\\t\", compression=\"gzip\", na_values=\"\\\\N\", nrows=500000\n",
    ")\n",
    "\n",
    "# Sort both dataframes by 'tconst' and reset the index\n",
    "title_basics  = title_basics.sort_values(\"tconst\", kind=\"mergesort\").reset_index(drop=True)\n",
    "title_ratings = title_ratings.sort_values(\"tconst\", kind=\"mergesort\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b905d",
   "metadata": {
    "id": "1c2b905d"
   },
   "source": [
    "## Part 1: Exploration and Data Cleaning\n",
    "\n",
    "Let's start by inspecting the `title_basics` `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gtD1XrLqaDMw",
   "metadata": {
    "id": "gtD1XrLqaDMw"
   },
   "source": [
    "### Q 1.1\n",
    "\n",
    "How many columns are in the `title_basics` `DataFrame`?\n",
    "\n",
    "What is the data type of the startYear column? Does this make sense?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f62b2b",
   "metadata": {
    "id": "79f62b2b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7Tksys_baYIi",
   "metadata": {
    "id": "7Tksys_baYIi"
   },
   "source": [
    "### Q1.2\n",
    "\n",
    "What is the value in 101st row of the `primaryTitle` column of the `title_basics` `DataFrame`? *HINT: Recall that* `DataFrame` *uses 0-indexing*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10583971",
   "metadata": {
    "id": "10583971"
   },
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kcO_Aylsali-",
   "metadata": {
    "id": "kcO_Aylsali-"
   },
   "source": [
    "### Q1.3\n",
    "\n",
    "Display the first 3 rows and the last 6 rows of the `title_basics` `DataFrame` as a single `DataFrame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617e365",
   "metadata": {
    "id": "3617e365"
   },
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kHTuCDb6ayit",
   "metadata": {
    "id": "kHTuCDb6ayit"
   },
   "source": [
    "### Q1.4\n",
    "\n",
    "How many unique `titleTypes` are there in the `title_basics` `DataFrame`? Which is the most common?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef57e4c",
   "metadata": {
    "id": "0ef57e4c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad14906b",
   "metadata": {
    "id": "ad14906b"
   },
   "source": [
    "Now let's practice some common `DataFrame` modifications.\n",
    "\n",
    "### Q1.5\n",
    "\n",
    "Remove the `originalTitle` and `endYear` columns from the `title_basics` `DataFrame`. Make sure that the columns are permanently removed from the `title_basics` `DataFrame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79f93f",
   "metadata": {
    "id": "7e79f93f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "title_basics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XctoqlYkbUvj",
   "metadata": {
    "id": "XctoqlYkbUvj"
   },
   "source": [
    "### Q1.6\n",
    "\n",
    "Rename `primaryTitle` to `title` and `startYear` to `year` in the `title_basics` `DataFrame`. Make sure that the changes are reflected permanently in the `title_basics` `DataFrame`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139da0ac",
   "metadata": {
    "id": "139da0ac"
   },
   "outputs": [],
   "source": [
    "\n",
    "title_basics = # YOUR CODE HERE\n",
    "\n",
    "title_basics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8c08d",
   "metadata": {
    "id": "b2f8c08d"
   },
   "source": [
    "### Q1.7\n",
    "\n",
    "A crucial step in most data processing pipelines for machine learning is dealing with missing or corrupted data. Often, these missing values are represented as a `NaN` (not a number).\n",
    "\n",
    "Sometimes in the context of machine learning we'd want to estimate a value for a missing feature rather than remove that sample point entirely. Can you think of some simple ways in which we could perform that estimation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qzRHVjWxcDBz",
   "metadata": {
    "id": "qzRHVjWxcDBz"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_GxonqpAcJi3",
   "metadata": {
    "id": "_GxonqpAcJi3"
   },
   "source": [
    "### Q1.8\n",
    "\n",
    "Remove all rows from the `title_basics` `DataFrame` where `runtimeMinutes` or `year` is `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9de4a",
   "metadata": {
    "id": "45b9de4a"
   },
   "outputs": [],
   "source": [
    "\n",
    "initial_length = title_basics.shape[0]\n",
    "\n",
    "title_basics = # YOUR CODE HERE\n",
    "\n",
    "final_length = title_basics.shape[0]\n",
    "\n",
    "print(f\"{initial_length - final_length} rows removed from dataframe\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ghadqccZy",
   "metadata": {
    "id": "af2ghadqccZy"
   },
   "source": [
    "### Q1.9\n",
    "\n",
    "Change the data type of the `year` column in the `title_basics` `DataFrame` to something that makes more sense. Then confirm that the change is permanently applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e3612b",
   "metadata": {
    "id": "26e3612b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f65dc",
   "metadata": {
    "id": "8a7f65dc"
   },
   "source": [
    "Let's practice some more basic filtering and sorting now.\n",
    "\n",
    "### Q1.10\n",
    "\n",
    "Extract the feature films (`titleType == \"movie\"`) released in 1954 from the `title_basics` `DataFrame` (save this as a new `DataFrame`, `feature_films_1954`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3165a21",
   "metadata": {
    "id": "a3165a21"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "feature_films_1954.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "byEsV1GWdACD",
   "metadata": {
    "id": "byEsV1GWdACD"
   },
   "source": [
    "### Q1.11\n",
    "\n",
    "Among the feature films from 1954, which film has the longest runtime? Return its `title` and `runtimeMinutes` as a `DataFrame` extracted from the `feature_films_1954` `DataFrame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c504fd3",
   "metadata": {
    "id": "7c504fd3"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wZ-0OLfLeVE0",
   "metadata": {
    "id": "wZ-0OLfLeVE0"
   },
   "source": [
    "## Part 2: Complex Modifications, Aggregations, Merging, and Plotting\n",
    "\n",
    "Let's first modify the `title_basics` `DataFrame` so that we have one genre in for each row by duplicating rows that have multiple genres. [`df.explode`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html) will be helpful for this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PjJ6mBTZeLj5",
   "metadata": {
    "id": "PjJ6mBTZeLj5"
   },
   "outputs": [],
   "source": [
    "# Split the genres string into a list of genres\n",
    "title_basics['genres'] = title_basics['genres'].str.split(',')\n",
    "# Explode the list of genres into separate rows\n",
    "title_basics = title_basics.explode('genres')\n",
    "\n",
    "title_basics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9d62d",
   "metadata": {
    "id": "ddd9d62d"
   },
   "source": [
    "### Q2.1\n",
    "\n",
    "For each `genre` in the `title_basics` `DataFrame`, compute the mean runtime of feature films released since 1960.\n",
    "Show the five longest-mean genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba3b91",
   "metadata": {
    "id": "97ba3b91"
   },
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xzaSo6uCg2PP",
   "metadata": {
    "id": "xzaSo6uCg2PP"
   },
   "source": [
    "### Q2.2\n",
    "\n",
    "Merge the `title_ratings` `DataFrame` with the `title_basics` `DataFrame` by joining on the `tconst` column. How many titles are present in the `title_basics` `DataFrame` but not in the `title_ratings` `DataFrame`? Store the merged `DataFrame` as `merged_df`.\n",
    "\n",
    "**Hint:** Recall that because of the genre splitting, the number of titles is not equal to the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645f018",
   "metadata": {
    "id": "1645f018"
   },
   "outputs": [],
   "source": [
    "n_titles_basics = ... # YOUR CODE HERE\n",
    "\n",
    "merged_df = ... # YOUR CODE HERE\n",
    "print(merged_df.head())\n",
    "\n",
    "n_titles_merged = ... # YOUR CODE HERE\n",
    "\n",
    "print(f\"\\nNumber of titles in basics but not in ratings: {n_titles_basics - n_titles_merged}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R91YICJXhOFb",
   "metadata": {
    "id": "R91YICJXhOFb"
   },
   "source": [
    "### Q2.3\n",
    "\n",
    "Using the `merged_df` `DataFrame` and plotly express, create an interactive scatter plot of the `runtimeMinutes` vs. `numVotes` for movies in the `merged_df` `DataFrame`.\n",
    "Color the points by the `year` of the movie and add a title and axis labels to the plot. Also, make sure the movie title is visible when hovering over the\n",
    "data points.\n",
    "\n",
    "**Note:** To make the data easier to visualize, we take a sample of just 2000 movies. That's why you may not see your favorites on this plot. It's important not to change the random state as you'll end up getting different results for the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38704f50",
   "metadata": {
    "id": "38704f50"
   },
   "outputs": [],
   "source": [
    "sampled_df = merged_df[merged_df['titleType'] == 'movie'].sample(n=2000, random_state=SEED)\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab6ba0",
   "metadata": {
    "id": "bdab6ba0"
   },
   "source": [
    "### Q2.4\n",
    "\n",
    "Describe any trends you see in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FlOss9mjicpU",
   "metadata": {
    "id": "FlOss9mjicpU"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2daf402",
   "metadata": {
    "id": "c2daf402"
   },
   "source": [
    "### Q2.5\n",
    "Which two movies in the plot received the most votes and had the longest runtime, respectively? When were they each released?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z02MGounidW2",
   "metadata": {
    "id": "z02MGounidW2"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4398a67",
   "metadata": {
    "id": "f4398a67"
   },
   "source": [
    "# Part 3: Finding the perfect movie\n",
    "\n",
    "Aakarsh has spent his whole summer brainrotting and doomscrolling, so now his attention span is COOKED. He wants to pick a movie to watch tonight but wants to make sure it isn't so long he gets bored. He decides to construct a Brainrot Score (BRS) to help him find the perfect movie:\n",
    "\n",
    "$$BRS = \\frac{\\text{averageRating}}{\\sqrt{\\text{runtimeMinutes}}}$$\n",
    "\n",
    "He also wants to make sure the following criteria hold:\n",
    "- The title should be a *movie* made in 1980 or later.\n",
    "- It must have at least 10000 votes.\n",
    "- It must be in the `History`, `Thriller`, or `Comedy` genres.\n",
    "\n",
    "Can you help Aakarsh out by finding the 3 best movies by BRS in each of his preferred genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21efe40a",
   "metadata": {
    "id": "21efe40a"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
